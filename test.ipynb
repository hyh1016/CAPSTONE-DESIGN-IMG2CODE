{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from os.path import basename\n",
    "from pix2code.model.classes.Sampler import *\n",
    "from pix2code.model.classes.model.pix2code import *\n",
    "from pix2code.model.classes.model.pix2code_v1 import *\n",
    "from pix2code.model.classes.model.pix2code_v1_Bi_GRU import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\optimizer_v2\\rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# trained_weights_path = 'pix2code/bin'\n",
    "trained_weights_path = 'pix2code/bin/tag_extension/6_pix2code_all_tag_early'\n",
    "\n",
    "meta_dataset = np.load(\"{}/meta_dataset.npy\".format(trained_weights_path), allow_pickle=True)\n",
    "input_shape = meta_dataset[0]\n",
    "output_size = meta_dataset[1]\n",
    "\n",
    "model = pix2code_v1_Bi_GRU(input_shape, output_size, trained_weights_path)\n",
    "model.load('pix2code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 23\n",
      "Input shape: (256, 256, 3)\n",
      "Output size: 23\n"
     ]
    }
   ],
   "source": [
    "sampler = Sampler(trained_weights_path, input_shape, output_size, CONTEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:25<00:00,  3.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# dataGenerator/data/png/ 폴더 파일 리스트\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "input_path = 'dataGenerator/data/training_set_tag_extension/png/'\n",
    "output_path = 'dataGenerator/data/training_set_tag_extension/dsl_predict/'\n",
    "file_list = os.listdir(input_path)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for input_file in tqdm(file_list):\n",
    "    file_name = basename(input_file)[:basename(input_file).find(\".\")]\n",
    "    # print(file_name)\n",
    "    evaluation_img = Utils.get_preprocessed_img(input_path + input_file, IMAGE_SIZE)\n",
    "    result, _ = sampler.predict_greedy(model, np.array([evaluation_img]))\n",
    "    result = result.replace('<START>', '').replace('<END>', '').replace('{', ' {').replace(',', ', ')\n",
    "    with open(f'{output_path}{file_name}.gui', 'w') as f:\n",
    "        f.write(result)\n",
    "    # print(\"Result greedy: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 22\n",
      "Input shape: (256, 256, 3)\n",
      "Output size: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:40:38<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from os.path import basename\n",
    "from pix2code.model.classes.Sampler import *\n",
    "from pix2code.model.classes.model.pix2code import *\n",
    "from pix2code.model.classes.model.pix2code_v1 import *\n",
    "from pix2code.model.classes.model.pix2code_v1_Bi_GRU import *\n",
    "# trained_weights_path = 'pix2code/bin'\n",
    "trained_weights_path = 'pix2code/bin/tag_extension/3_button_color'\n",
    "\n",
    "meta_dataset = np.load(\"{}/meta_dataset.npy\".format(trained_weights_path), allow_pickle=True)\n",
    "input_shape = meta_dataset[0]\n",
    "output_size = meta_dataset[1]\n",
    "\n",
    "model = pix2code_v1_Bi_GRU(input_shape, output_size, trained_weights_path)\n",
    "model.load('pix2code')\n",
    "sampler = Sampler(trained_weights_path, input_shape, output_size, CONTEXT_LENGTH)\n",
    "# dataGenerator/data/png/ 폴더 파일 리스트\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "input_path = 'dataGenerator/data/3_color/png/'\n",
    "output_path = 'dataGenerator/data/3_color/dsl_predict/'\n",
    "file_list = os.listdir(input_path)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for input_file in tqdm(file_list):\n",
    "    file_name = basename(input_file)[:basename(input_file).find(\".\")]\n",
    "    # print(file_name)\n",
    "    evaluation_img = Utils.get_preprocessed_img(input_path + input_file, IMAGE_SIZE)\n",
    "    result, _ = sampler.predict_greedy(model, np.array([evaluation_img]))\n",
    "    result = result.replace('<START>', '').replace('<END>', '').replace('{', ' {').replace(',', ', ')\n",
    "    with open(f'{output_path}{file_name}.gui', 'w') as f:\n",
    "        f.write(result)\n",
    "    # print(\"Result greedy: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 21\n",
      "Input shape: (256, 256, 3)\n",
      "Output size: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:52:25<00:00,  3.37s/it]  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from os.path import basename\n",
    "from pix2code.model.classes.Sampler import *\n",
    "from pix2code.model.classes.model.pix2code import *\n",
    "from pix2code.model.classes.model.pix2code_v1 import *\n",
    "from pix2code.model.classes.model.pix2code_v1_Bi_GRU import *\n",
    "# trained_weights_path = 'pix2code/bin'\n",
    "trained_weights_path = 'pix2code/bin/tag_extension/4_triple'\n",
    "\n",
    "meta_dataset = np.load(\"{}/meta_dataset.npy\".format(trained_weights_path), allow_pickle=True)\n",
    "input_shape = meta_dataset[0]\n",
    "output_size = meta_dataset[1]\n",
    "\n",
    "model = pix2code_v1_Bi_GRU(input_shape, output_size, trained_weights_path)\n",
    "model.load('pix2code')\n",
    "sampler = Sampler(trained_weights_path, input_shape, output_size, CONTEXT_LENGTH)\n",
    "# dataGenerator/data/png/ 폴더 파일 리스트\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "input_path = 'dataGenerator/data/4_triple/png/'\n",
    "output_path = 'dataGenerator/data/4_triple/dsl_predict/'\n",
    "file_list = os.listdir(input_path)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "for input_file in tqdm(file_list):\n",
    "    file_name = basename(input_file)[:basename(input_file).find(\".\")]\n",
    "    # print(file_name)\n",
    "    evaluation_img = Utils.get_preprocessed_img(input_path + input_file, IMAGE_SIZE)\n",
    "    result, _ = sampler.predict_greedy(model, np.array([evaluation_img]))\n",
    "    result = result.replace('<START>', '').replace('<END>', '').replace('{', ' {').replace(',', ', ')\n",
    "    with open(f'{output_path}{file_name}.gui', 'w') as f:\n",
    "        f.write(result)\n",
    "    # print(\"Result greedy: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Process, Pool\n",
    "\n",
    "# queue 입력 데이터\n",
    "# [input_img, current_context, id]\n",
    "# 마지막은 -1\n",
    "inQ = Queue()\n",
    "outQ = Queue()\n",
    "\n",
    "def doPredict(model:pix2code_v1_Bi_GRU, input_imgs, current_contexts, ids, outQueue:Queue):\n",
    "    result = model.predict_batch(input_imgs, current_contexts)\n",
    "    output = {}\n",
    "    for i in range(len(result)):\n",
    "        output[ids[i]] = result[i]\n",
    "    for i in range(len(result)):\n",
    "        outQueue.put(output)\n",
    "\n",
    "def worker(inQueue:Queue, outQueue:Queue, model:pix2code_v1_Bi_GRU):\n",
    "    input_imgs = np.array()\n",
    "    current_contexts = np.array()\n",
    "    ids = []\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        data = inQueue.get()\n",
    "        if data is None:\n",
    "            continue\n",
    "        elif data==-1:\n",
    "            break\n",
    "        # 마지막 데이터들 처리\n",
    "        elif data==0:\n",
    "            doPredict(model, input_imgs, current_contexts, ids, outQueue)\n",
    "            input_imgs = np.array()\n",
    "            current_contexts = np.array()\n",
    "            ids = []\n",
    "            cnt = 0\n",
    "        if cnt == 10:\n",
    "            doPredict(model, input_imgs, current_contexts, ids, outQueue)\n",
    "            input_imgs = np.array()\n",
    "            current_contexts = np.array()\n",
    "            ids = []\n",
    "            cnt = 0\n",
    "        input_imgs.append(data[0])\n",
    "        current_contexts.append(data[1])\n",
    "        ids.append(data[2])\n",
    "        cnt += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_greedy_multi(model, input_img, inQueue:Queue, outQueue:Queue, id, voc:Vocabulary, input_shape, output_size, context_length, require_sparse_label=True, sequence_length=150, verbose=False):\n",
    "    current_context = [voc.vocabulary[PLACEHOLDER]] * (context_length - 1)\n",
    "    current_context.append(voc.vocabulary[START_TOKEN])\n",
    "    if require_sparse_label:\n",
    "        current_context = Utils.sparsify(current_context, output_size)\n",
    "\n",
    "    predictions = START_TOKEN\n",
    "    out_probas = []\n",
    "\n",
    "    for i in range(0, sequence_length):\n",
    "        if verbose:\n",
    "            print(\"predicting {}/{}...\".format(i, sequence_length))\n",
    "\n",
    "        ##################\n",
    "        inQueue.put((input_img, np.array([current_context], id)))\n",
    "        probases = outQueue.get()\n",
    "        probas = probases[id]\n",
    "        ##################\n",
    "        # probas = model.predict(input_img, np.array([current_context]))\n",
    "        prediction = np.argmax(probas)\n",
    "        out_probas.append(probas)\n",
    "\n",
    "        new_context = []\n",
    "        for j in range(1, context_length):\n",
    "            new_context.append(current_context[j])\n",
    "\n",
    "        if require_sparse_label:\n",
    "            sparse_label = np.zeros(output_size)\n",
    "            sparse_label[prediction] = 1\n",
    "            new_context.append(sparse_label)\n",
    "        else:\n",
    "            new_context.append(prediction)\n",
    "\n",
    "        current_context = new_context\n",
    "\n",
    "        predictions += voc.token_lookup[prediction]\n",
    "\n",
    "        if voc.token_lookup[prediction] == END_TOKEN:\n",
    "            break\n",
    "\n",
    "    return predictions, out_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "416c1d3ac02f713a9a5502b63071185a8d76ad9cf71f6b904773d8aa1e5d8d6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
